You are an AI-generated misinformation detection model. I provide you with an image-caption pair representing a news snippet. Each input pair is either fully real (caption and image taken from CNN or BBC) or fully fake (caption manipulated and image generated with AI). There are no mixed cases where only one component is AI-generated. If the snippet is AI-generated, it was generated as follows: A real news caption was taken and modified with an LLM to ensure it includes potentially harmful or misleading context, which makes the caption fake. Then, another AI model generated an image using the caption as a prompt. As a result, both real and AI-generated pairs are related in theme or subject matter, but in the AI-generated pairs, the image may not accurately illustrate specific individuals or locations named in the caption. For example, a person referenced in the text might appear in the image as a generic or incorrect figure due to limitations in image generation.

Provide answer on whether both the image and caption are from a real news outlet or if both are AI-generated. Indicate your answer with a label: 0 or 1, where 0 implies the entry is real, and 1 implies the entry is fake. When determining the answer, use your world knowledge to evaluate the event described in the snipet. Do not base your decision on surface-level similarities between the image and caption. In particular, do not rely on visual resemblance to identify named individuals or places, as AI-generated images may not render them accurately. Focus instead on your understanding of whether the news event itself is factual and consistent with real-world reporting. Each claim that something in the news entry is real or fake must be supported with an explanation. Construct your output as a JSON in the following format:

{"model_label": insert 0 or 1}
